{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaciones y definiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from fastapi import FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de movies_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('data/movies_dataset.csv', sep=',', encoding='utf-8', low_memory=False)\n",
    "credits_df = pd.read_csv('data/credits.csv', sep=',', encoding='utf-8', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos asegúramos de que ambas columnas 'id' sean del mismo tipo ver [DD]('doc/Diccionario de Datos - PIMLOps.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['id'] = movies_df['id'].astype(str)\n",
    "credits_df['id'] = credits_df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unir los datasets usando la columna 'id' como clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(movies_df, credits_df, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos campos, como belongs_to_collection, production_companies y otros [DD]('doc/Diccionario de Datos - PIMLOps.xlsx') están anidados, esto es o bien tienen un diccionario o una lista como valores en cada fila, ¡deberán desanidarlos para poder y unirlos al dataset de nuevo hacer alguna de las consultas de la API! O bien buscar la manera de acceder a esos datos sin desanidarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para desanidar un campo JSON\n",
    "# Pendiente de aplicación\n",
    "def desanidar_json(valor):\n",
    "    try:\n",
    "        return json.loads(valor)\n",
    "    except (TypeError, ValueError):\n",
    "        return {} # O [] si esperas listas\n",
    "\n",
    "# Desanidar los campos relevantes (reemplaza 'campo1', 'campo2', etc.)\n",
    "campos_anidados = ['belongs_to_collection', 'production_companies', 'genres', 'production_countries', 'spoken_languages']\n",
    "for campo in campos_anidados:\n",
    "    df[campo] = df[campo].apply(desanidar_json)\n",
    "\n",
    "# Ejemplo de cómo acceder a datos desanidados:\n",
    "#df['production_companies'][0][0]['name']  # Accede al nombre de la primera compañía de producción de la primera película"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores nulos de los campos revenue, budget deben ser rellenados por el número 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores nulos de las columnas 'revenue' y 'budget' con 0\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "df['budget'] = df['budget'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores nulos del campo release date deben eliminarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las filas donde 'release_date' tenga valores nulos\n",
    "df = df.dropna(subset=['release_date'])\n",
    "print(df['release_date'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De haber fechas, deberán tener el formato AAAA-mm-dd, además deberán crear la columna release_year donde extraerán el año de la fecha de estreno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir la columna 'release_date' al formato datetime:\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "\n",
    "#Formatear la columna 'release_date' a 'AAAA-mm-dd':\n",
    "df['release_date'] = df['release_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#Crear la columna 'release_year' extrayendo el año:\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], format='%Y-%m-%d', errors='coerce')\n",
    "df['release_year'] = df['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear la columna con el retorno de inversión, llamada return con los campos revenue y budget, dividiendo estas dos últimas revenue / budget, cuando no hay datos disponibles para calcularlo, deberá tomar el valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas 'revenue' y 'budget' a tipo numérico, manejando los valores que no se pueden convertir\n",
    "df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')  # Convertir a float, poner NaN si no es posible\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')  # Convertir a float, poner NaN si no es posible\n",
    "\n",
    "# Reemplazar valores NaN con 0 si es necesario\n",
    "df['revenue'] = df['revenue'].fillna(0)\n",
    "df['budget'] = df['budget'].fillna(0)\n",
    "\n",
    "# Calcular el retorno de inversión\n",
    "# Usamos np.where para manejar las divisiones por cero y los casos donde revenue es cero\n",
    "df['return'] = np.where(df['budget'] != 0, df['revenue'] / df['budget'], 0)\n",
    "\n",
    "# Asegurarse de que si tanto 'revenue' como 'budget' son 0, el retorno también sea 0\n",
    "df['return'] = np.where((df['revenue'] == 0) & (df['budget'] == 0), 0, df['return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar las columnas que no serán utilizadas, video,imdb_id,adult,original_title,poster_path y homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_remover = ['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n",
    "df = df.drop(columns=columnas_a_remover, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 45451 entries, 0 to 45537\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   belongs_to_collection  45451 non-null  object        \n",
      " 1   budget                 45451 non-null  int64         \n",
      " 2   genres                 45451 non-null  object        \n",
      " 3   id                     45451 non-null  object        \n",
      " 4   original_language      45440 non-null  object        \n",
      " 5   overview               44510 non-null  object        \n",
      " 6   popularity             45451 non-null  object        \n",
      " 7   production_companies   45451 non-null  object        \n",
      " 8   production_countries   45451 non-null  object        \n",
      " 9   release_date           45451 non-null  datetime64[ns]\n",
      " 10  revenue                45451 non-null  float64       \n",
      " 11  runtime                45205 non-null  float64       \n",
      " 12  spoken_languages       45451 non-null  object        \n",
      " 13  status                 45371 non-null  object        \n",
      " 14  tagline                20425 non-null  object        \n",
      " 15  title                  45451 non-null  object        \n",
      " 16  vote_average           45451 non-null  float64       \n",
      " 17  vote_count             45451 non-null  float64       \n",
      " 18  cast                   45451 non-null  object        \n",
      " 19  crew                   45451 non-null  object        \n",
      " 20  release_year           45451 non-null  int32         \n",
      " 21  return                 45451 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(5), int32(1), int64(1), object(14)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  release_date  mes  dia_semana_num  anio mes_nombre_esp dia_semana_nombre_esp\n",
      "0   1995-10-30   10               0  1995        October                 lunes\n",
      "1   1995-12-15   12               4  1995       December               viernes\n",
      "2   1995-12-22   12               4  1995       December               viernes\n",
      "3   1995-12-22   12               4  1995       December               viernes\n",
      "4   1995-02-10    2               4  1995       February               viernes\n"
     ]
    }
   ],
   "source": [
    "# Asegurarse de que la columna 'release_date' existe en el DataFrame\n",
    "if 'release_date' in df.columns:\n",
    "    # Convertir la columna 'release_date' a tipo datetime\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "\n",
    "    # Extraer el mes (en formato numérico)\n",
    "    df['mes'] = df['release_date'].dt.month\n",
    "\n",
    "    # Extraer el día de la semana (en formato numérico, lunes=0, domingo=6)\n",
    "    df['dia_semana_num'] = df['release_date'].dt.dayofweek\n",
    "\n",
    "    # Extraer el año\n",
    "    df['anio'] = df['release_date'].dt.year\n",
    "\n",
    "    # Para obtener el nombre del mes en español, se puede usar la configuración regional o un mapeo\n",
    "    df['mes_nombre_esp'] = df['mes'].apply(lambda x: pd.to_datetime(x, format='%m').strftime('%B') if pd.notna(x) else '')\n",
    "\n",
    "    # Para obtener el nombre del día de la semana en español, se puede usar un mapeo\n",
    "    dias_semana_esp = {0: 'lunes', 1: 'martes', 2: 'miércoles', 3: 'jueves', 4: 'viernes', 5: 'sábado', 6: 'domingo'}\n",
    "    df['dia_semana_nombre_esp'] = df['dia_semana_num'].map(dias_semana_esp)\n",
    "\n",
    "    print(df[['release_date', 'mes', 'dia_semana_num', 'anio', 'mes_nombre_esp', 'dia_semana_nombre_esp']].head())\n",
    "else:\n",
    "    print(\"La columna 'release_date' no se encontró en el DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Endpoint /cantidad_filmaciones_mes/{Mes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/cantidad_filmaciones_mes/{Mes}\")\n",
    "async def cantidad_filmaciones_mes(Mes: str):\n",
    "    # Mapeo de nombres de meses en español a formato de Pandas\n",
    "    meses_esp_a_num = {'enero': 1, 'febrero': 2, 'marzo': 3, 'abril': 4, 'mayo': 5, 'junio': 6,\n",
    "                        'julio': 7, 'agosto': 8, 'septiembre': 9, 'octubre': 10, 'noviembre': 11, 'diciembre': 12}\n",
    "    mes_num = meses_esp_a_num.get(Mes.lower())\n",
    "    if mes_num:\n",
    "        cantidad = len(df[df['mes'] == mes_num])\n",
    "        return {\"Mes\": Mes, \"cantidad\": cantidad}\n",
    "    else:\n",
    "        return {\"error\": f\"El mes '{Mes}' no es válido.\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Endpoint /cantidad_filmaciones_dia/{Dia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/cantidad_filmaciones_dia/{Dia}\")\n",
    "async def cantidad_filmaciones_dia(Dia: str):\n",
    "    # Mapeo de nombres de días de la semana en español a números de Pandas\n",
    "    dias_esp_a_num = {'lunes': 0, 'martes': 1, 'miércoles': 2, 'jueves': 3, 'viernes': 4, 'sábado': 5, 'domingo': 6}\n",
    "    dia_num = dias_esp_a_num.get(Dia.lower())\n",
    "    if dia_num is not None:\n",
    "        cantidad = len(df[df['dia_semana_num'] == dia_num])\n",
    "        return {\"Dia\": Dia, \"cantidad\": cantidad}\n",
    "    else:\n",
    "        return {\"error\": f\"El día '{Dia}' no es válido.\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Endpoint /score_titulo/{titulo_de_la_filmacion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/score_titulo/{titulo_de_la_filmacion}\")\n",
    "async def score_titulo(titulo_de_la_filmacion: str):\n",
    "    pelicula = df[df['title'].str.lower() == titulo_de_la_filmacion.lower()]\n",
    "    if not pelicula.empty:\n",
    "        # Considerar devolver la primera coincidencia si hay múltiples\n",
    "        pelicula = pelicula.iloc[0]\n",
    "        return {\n",
    "            \"titulo\": pelicula['title'],\n",
    "            \"anio_estreno\": int(pelicula['anio']) if pd.notna(pelicula['anio']) else None,\n",
    "            \"score\": pelicula['popularity']\n",
    "        }\n",
    "    else:\n",
    "        return {\"mensaje\": f\"No se encontró la película con el título '{titulo_de_la_filmacion}'.\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Endpoint /votos_titulo/{titulo_de_la_filmacion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/votos_titulo/{titulo_de_la_filmacion}\")\n",
    "async def votos_titulo(titulo_de_la_filmacion: str):\n",
    "    pelicula = df[df['title'].str.lower() == titulo_de_la_filmacion.lower()]\n",
    "    if not pelicula.empty:\n",
    "        pelicula = pelicula.iloc[0]\n",
    "        cantidad_votos = pelicula['vote_count']\n",
    "        if cantidad_votos >= 2000:\n",
    "            return {\n",
    "                \"titulo\": pelicula['title'],\n",
    "                \"cantidad_votos\": int(cantidad_votos) if pd.notna(cantidad_votos) else None,\n",
    "                \"promedio_votos\": pelicula['vote_average']\n",
    "            }\n",
    "        else:\n",
    "            return {\"mensaje\": f\"La película '{titulo_de_la_filmacion}' no cumple con las valoraciones mínimas (>= 2000 votos).\"}\n",
    "    else:\n",
    "        return {\"mensaje\": f\"No se encontró la película con el título '{titulo_de_la_filmacion}'.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Endpoint /get_actor/{nombre_actor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_actor/{nombre_actor}\")\n",
    "async def get_actor(nombre_actor: str):\n",
    "    peliculas_actor = df[df['cast'].apply(lambda x: nombre_actor.lower() in str(x).lower())]\n",
    "    if not peliculas_actor.empty:\n",
    "        retornos = peliculas_actor.apply(lambda row: row['revenue'] - row['budget'] if pd.notna(row['revenue']) and pd.notna(row['budget']) else np.nan, axis=1)\n",
    "        retornos_validos = retornos.dropna()\n",
    "        cantidad_peliculas = len(peliculas_actor)\n",
    "        retorno_total = retornos_validos.sum()\n",
    "        promedio_retorno = retornos_validos.mean() if not retornos_validos.empty else 0\n",
    "        return {\n",
    "            \"nombre_actor\": nombre_actor,\n",
    "            \"cantidad_filmaciones\": cantidad_peliculas,\n",
    "            \"retorno_total\": retorno_total,\n",
    "            \"promedio_retorno\": promedio_retorno\n",
    "        }\n",
    "    else:\n",
    "        return {\"mensaje\": f\"No se encontró al actor con el nombre '{nombre_actor}' en las filmaciones.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Endpoint /get_director/{nombre_director}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_director/{nombre_director}\")\n",
    "async def get_director(nombre_director: str):\n",
    "    peliculas_director = df[df['crew'].apply(lambda x: nombre_director.lower() in str(x).lower() and 'director' in str(x).lower())]\n",
    "    if not peliculas_director.empty:\n",
    "        retorno_total = peliculas_director.apply(lambda row: row['revenue'] - row['budget'] if pd.notna(row['revenue']) and pd.notna(row['budget']) else np.nan, axis=1).dropna().sum()\n",
    "        peliculas_info = []\n",
    "        for index, pelicula in peliculas_director.iterrows():\n",
    "            retorno_individual = pelicula['revenue'] - pelicula['budget'] if pd.notna(pelicula['revenue']) and pd.notna(pelicula['budget']) else None\n",
    "            ganancia = pelicula['revenue'] if pd.notna(pelicula['revenue']) else None\n",
    "            costo = pelicula['budget'] if pd.notna(pelicula['budget']) else None\n",
    "            fecha_lanzamiento = pelicula['release_date'].isoformat() if pd.notna(pelicula['release_date']) else None\n",
    "            peliculas_info.append({\n",
    "                \"titulo\": pelicula['title'],\n",
    "                \"fecha_lanzamiento\": fecha_lanzamiento,\n",
    "                \"retorno_individual\": retorno_individual,\n",
    "                \"costo\": costo,\n",
    "                \"ganancia\": ganancia\n",
    "            })\n",
    "        return {\n",
    "            \"nombre_director\": nombre_director,\n",
    "            \"retorno_total\": retorno_total,\n",
    "            \"peliculas\": peliculas_info\n",
    "        }\n",
    "    else:\n",
    "        return {\"mensaje\": f\"No se encontró al director con el nombre '{nombre_director}'.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de recomendación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Preparar los datos: vectorización de los títulos de las películas\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['title'].fillna(''))\n",
    "\n",
    "# Calcular similitud de coseno entre las películas\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Función de recomendación\n",
    "def recomendacion(titulo):\n",
    "    try:\n",
    "        # Encontrar el índice de la película ingresada\n",
    "        idx = df[df['title'].str.lower() == titulo.lower()].index[0]\n",
    "        # Obtener similitudes de esa película con todas las demás\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        # Ordenar películas por puntaje de similitud\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        # Obtener los índices de las 5 películas más similares\n",
    "        top_indices = [i[0] for i in sim_scores[1:6]]\n",
    "        # Retornar los títulos de las películas más similares\n",
    "        return df.iloc[top_indices]['title'].tolist()\n",
    "    except IndexError:\n",
    "        return \"Título no encontrado en el dataset. Por favor, verifica el nombre e intenta nuevamente.\"\n",
    "\n",
    "# Ejemplo de uso\n",
    "#titulo_busqueda = \"Titanic\"\n",
    "#print(recomendacion(titulo_busqueda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener todos los idiomas\n",
    "#python -m nltk.downloader popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idiomas únicos: ['', 'ქართული', 'Malti', 'پښتو', 'Somali', 'Català', 'Український', '普通话', 'اردو', 'Nederlands', 'العربية', 'ελληνικά', 'ਪੰਜਾਬੀ', 'Bahasa indonesia', 'shqip', 'Deutsch', '日本語', 'Dansk', 'Hausa', 'svenska', 'No Language', 'తెలుగు', 'עִבְרִית', 'Hrvatski', 'Latviešu', 'Bamanankan', 'Gaeilge', 'Norsk', 'Azərbaycan', 'Polski', 'Esperanto', 'Eesti', 'বাংলা', 'Fulfulde', 'Magyar', 'ภาษาไทย', 'isiZulu', 'Wolof', 'Latin', 'Kiswahili', 'Tiếng Việt', 'беларуская мова', 'Bahasa melayu', 'euskera', 'Pусский', 'suomi', 'English', 'Italiano', 'فارسی', '한국어/조선말', 'Română', 'Bokmål', 'Galego', 'български език', 'Español', 'Slovenščina', '??????', 'हिन्दी', 'Slovenčina', 'Afrikaans', 'қазақ', 'Português', 'Srpski', 'Cymraeg', 'Türkçe', '?????', '广州话 / 廣州話', 'ozbek', 'Český', 'Kinyarwanda', 'Français', 'Íslenska', 'Bosanski', 'தமிழ்']\n"
     ]
    }
   ],
   "source": [
    "def obtener_idiomas(df):\n",
    "    idiomas = set()  # Usamos un conjunto para evitar duplicados\n",
    "    \n",
    "    for entrada in df['spoken_languages'].dropna():\n",
    "        try:\n",
    "            # Convertir la cadena de texto en una lista de diccionarios\n",
    "            lista_idiomas = json.loads(entrada.replace(\"'\", \"\\\"\"))  # Reemplazar comillas simples por dobles\n",
    "            # Extraer el campo 'name' de cada diccionario\n",
    "            idiomas.update(lang['name'] for lang in lista_idiomas if 'name' in lang)\n",
    "        except json.JSONDecodeError:\n",
    "            # Manejar errores de formato en el JSON\n",
    "            continue\n",
    "    \n",
    "    return list(idiomas)  # Convertir a lista antes de retornar\n",
    "\n",
    "# Llamar a la función\n",
    "idiomas_unicos = obtener_idiomas(movies_df)\n",
    "print(\"Idiomas únicos:\", idiomas_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecución y Prueba de la API\n",
    "Ejecución de la Aplicación con Uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#uvicorn.run(app, host=\"0.0.0.0\", port=8000, reload=True)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.0.0.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\uvicorn\\main.py:579\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\uvicorn\\server.py:66\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    #uvicorn.run(app, host=\"0.0.0.0\", port=8000, reload=True)\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
